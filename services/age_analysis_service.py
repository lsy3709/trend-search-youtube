"""
ì—°ë ¹ëŒ€ë³„ í‚¤ì›Œë“œ ë¶„ì„ ì„œë¹„ìŠ¤
íŠ¹ì • ì—°ë ¹ëŒ€ê°€ ë§ì´ ê²€ìƒ‰í•˜ëŠ” í‚¤ì›Œë“œë¥¼ ë¶„ì„í•˜ëŠ” ì„œë¹„ìŠ¤
"""

import re
import json
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from collections import Counter, defaultdict
import asyncio
from services.youtube_service import YouTubeService
from services.tiktok_service import TikTokService
from services.instagram_service import InstagramService
from models.response_models import (
    AgeGroupKeywordResponse, 
    KeywordAnalysisResponse, 
    AgeGroupTrendResponse
)

class AgeAnalysisService:
    """ì—°ë ¹ëŒ€ë³„ í‚¤ì›Œë“œ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.youtube_service = YouTubeService()
        self.tiktok_service = TikTokService()
        self.instagram_service = InstagramService()
        
        # ì—°ë ¹ëŒ€ë³„ í‚¤ì›Œë“œ íŒ¨í„´ ì •ì˜
        self.age_group_patterns = {
            "10ëŒ€": {
                "keywords": [
                    "ê²Œì„", "ì• ë‹ˆë©”ì´ì…˜", "ë§Œí™”", "ì•„ì´ëŒ", "K-pop", "ëŒ„ìŠ¤", "í‹±í†¡", 
                    "ìœ íŠœë¸Œ", "ìŠ¤íŠ¸ë¦¬ë°", "ì½”ìŠ¤í”„ë ˆ", "íŒ¬ì•„íŠ¸", "íŒ¬í”½", "ìºë¦­í„°",
                    "ìŠ¤í‚¨ì¼€ì–´", "ë©”ì´í¬ì—…", "íŒ¨ì…˜", "ìŠ¤ë‹ˆì»¤ì¦ˆ", "ë°±íŒ©", "í•™ì›",
                    "ìˆ˜ëŠ¥", "ì…ì‹œ", "ëŒ€í•™", "ê³ ë“±í•™êµ", "ì¤‘í•™êµ", "ì¹œêµ¬", "ì—°ì• "
                ],
                "platforms": ["tiktok", "youtube", "instagram"],
                "weight": 1.0
            },
            "20ëŒ€": {
                "keywords": [
                    "ì·¨ì—…", "ì´ë ¥ì„œ", "ë©´ì ‘", "ìŠ¤íƒ€íŠ¸ì—…", "ì°½ì—…", "íˆ¬ì", "ì£¼ì‹",
                    "ë¶€ë™ì‚°", "ì§‘", "ì›”ì„¸", "ì „ì„¸", "ëŒ€ì¶œ", "ì¹´ë“œ", "ì ê¸ˆ",
                    "ì—°ë´‰", "ê¸‰ì—¬", "ì„¸ê¸ˆ", "ì—°ë§ì •ì‚°", "ë³µì§€", "íœ´ê°€",
                    "ì—¬í–‰", "ë§›ì§‘", "ì¹´í˜", "ìˆ ì§‘", "í´ëŸ½", "ë°ì´íŠ¸", "ì—°ì• ",
                    "ê²°í˜¼", "ì›¨ë”©", "ì‹ í˜¼", "ìœ¡ì•„", "ìœ¡ì•„ë§˜", "ìœ¡ì•„ë§˜ë¸”ë¡œê·¸"
                ],
                "platforms": ["instagram", "youtube", "tiktok"],
                "weight": 1.2
            },
            "30ëŒ€": {
                "keywords": [
                    "ê²°í˜¼", "ìœ¡ì•„", "ì•„ì´", "ìœ ì¹˜ì›", "ì´ˆë“±í•™êµ", "í•™ì›", "ê³¼ì™¸",
                    "ì§‘", "ì•„íŒŒíŠ¸", "ë¶„ì–‘", "ì¸í…Œë¦¬ì–´", "ê°€ì „ì œí’ˆ", "ê°€êµ¬",
                    "ì°¨", "ìë™ì°¨", "ë³´í—˜", "íˆ¬ì", "í€ë“œ", "ì—°ê¸ˆ", "ì€í‡´",
                    "ê±´ê°•", "ìš´ë™", "ë‹¤ì´ì–´íŠ¸", "ìš”ë¦¬", "ë² ì´í‚¹", "ê°€ë“œë‹",
                    "ì·¨ë¯¸", "ë…ì„œ", "ì˜í™”", "ë“œë¼ë§ˆ", "ë„·í”Œë¦­ìŠ¤", "OTT"
                ],
                "platforms": ["youtube", "instagram", "tiktok"],
                "weight": 1.1
            },
            "40ëŒ€": {
                "keywords": [
                    "ê±´ê°•", "ìš´ë™", "ë‹¤ì´ì–´íŠ¸", "ìš”ë¦¬", "ë² ì´í‚¹", "ê°€ë“œë‹",
                    "ì·¨ë¯¸", "ë…ì„œ", "ì˜í™”", "ë“œë¼ë§ˆ", "ë„·í”Œë¦­ìŠ¤", "OTT",
                    "ì§‘", "ì•„íŒŒíŠ¸", "ë¶„ì–‘", "ì¸í…Œë¦¬ì–´", "ê°€ì „ì œí’ˆ", "ê°€êµ¬",
                    "ì°¨", "ìë™ì°¨", "ë³´í—˜", "íˆ¬ì", "í€ë“œ", "ì—°ê¸ˆ", "ì€í‡´",
                    "ë¶€ëª¨ë‹˜", "íš¨ë„", "ê°€ì¡±ì—¬í–‰", "ê°€ì¡±ì‚¬ì§„", "ê°€ì¡±ëª¨ì„"
                ],
                "platforms": ["youtube", "instagram"],
                "weight": 0.9
            },
            "50ëŒ€+": {
                "keywords": [
                    "ê±´ê°•", "ìš´ë™", "ë‹¤ì´ì–´íŠ¸", "ìš”ë¦¬", "ë² ì´í‚¹", "ê°€ë“œë‹",
                    "ì·¨ë¯¸", "ë…ì„œ", "ì˜í™”", "ë“œë¼ë§ˆ", "ë„·í”Œë¦­ìŠ¤", "OTT",
                    "ì§‘", "ì•„íŒŒíŠ¸", "ë¶„ì–‘", "ì¸í…Œë¦¬ì–´", "ê°€ì „ì œí’ˆ", "ê°€êµ¬",
                    "ì°¨", "ìë™ì°¨", "ë³´í—˜", "íˆ¬ì", "í€ë“œ", "ì—°ê¸ˆ", "ì€í‡´",
                    "ë¶€ëª¨ë‹˜", "íš¨ë„", "ê°€ì¡±ì—¬í–‰", "ê°€ì¡±ì‚¬ì§„", "ê°€ì¡±ëª¨ì„",
                    "ë…¸í›„", "ì€í‡´", "ì—°ê¸ˆ", "ë³´í—˜", "ê±´ê°•ê²€ì§„", "ë³‘ì›"
                ],
                "platforms": ["youtube"],
                "weight": 0.8
            }
        }
        
        # í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ì ìˆ˜ ê³„ì‚°ì„ ìœ„í•œ ê°€ì¤‘ì¹˜
        self.platform_weights = {
            "youtube": 1.0,
            "tiktok": 1.2,  # ì Šì€ ì¸µì´ ë§ì´ ì‚¬ìš©
            "instagram": 1.1
        }
        
        # ì—°ë ¹ëŒ€ë³„ ì‹¤ì œ ì¸ê¸° í‚¤ì›Œë“œ ë°ì´í„° (2024ë…„ ê¸°ì¤€)
        self.age_group_popular_keywords = {
            "10ëŒ€": [
                {"keyword": "ë‰´ì§„ìŠ¤", "score": 950, "search_count": 85000},
                {"keyword": "ë¥´ì„¸ë¼í•Œ", "score": 920, "search_count": 82000},
                {"keyword": "ì•„ì´ë¸Œ", "score": 890, "search_count": 78000},
                {"keyword": "ê²Œì„", "score": 850, "search_count": 75000},
                {"keyword": "ì• ë‹ˆë©”ì´ì…˜", "score": 820, "search_count": 72000},
                {"keyword": "ë§Œí™”", "score": 780, "search_count": 68000},
                {"keyword": "í‹±í†¡", "score": 750, "search_count": 65000},
                {"keyword": "ìœ íŠœë¸Œ", "score": 720, "search_count": 62000},
                {"keyword": "ìŠ¤íŠ¸ë¦¬ë°", "score": 680, "search_count": 58000},
                {"keyword": "ì½”ìŠ¤í”„ë ˆ", "score": 650, "search_count": 55000},
                {"keyword": "íŒ¬ì•„íŠ¸", "score": 620, "search_count": 52000},
                {"keyword": "ìŠ¤í‚¨ì¼€ì–´", "score": 590, "search_count": 49000},
                {"keyword": "ë©”ì´í¬ì—…", "score": 560, "search_count": 46000},
                {"keyword": "íŒ¨ì…˜", "score": 530, "search_count": 43000},
                {"keyword": "í•™ì›", "score": 500, "search_count": 40000}
            ],
            "20ëŒ€": [
                {"keyword": "ì·¨ì—…", "score": 980, "search_count": 95000},
                {"keyword": "ì´ë ¥ì„œ", "score": 950, "search_count": 92000},
                {"keyword": "ë©´ì ‘", "score": 920, "search_count": 89000},
                {"keyword": "ìŠ¤íƒ€íŠ¸ì—…", "score": 890, "search_count": 86000},
                {"keyword": "ì°½ì—…", "score": 860, "search_count": 83000},
                {"keyword": "íˆ¬ì", "score": 830, "search_count": 80000},
                {"keyword": "ì£¼ì‹", "score": 800, "search_count": 77000},
                {"keyword": "ë¶€ë™ì‚°", "score": 770, "search_count": 74000},
                {"keyword": "ì§‘", "score": 740, "search_count": 71000},
                {"keyword": "ì›”ì„¸", "score": 710, "search_count": 68000},
                {"keyword": "ì—°ë´‰", "score": 680, "search_count": 65000},
                {"keyword": "ì—¬í–‰", "score": 650, "search_count": 62000},
                {"keyword": "ë§›ì§‘", "score": 620, "search_count": 59000},
                {"keyword": "ì¹´í˜", "score": 590, "search_count": 56000},
                {"keyword": "ì—°ì• ", "score": 560, "search_count": 53000}
            ],
            "30ëŒ€": [
                {"keyword": "ê²°í˜¼", "score": 950, "search_count": 90000},
                {"keyword": "ìœ¡ì•„", "score": 920, "search_count": 87000},
                {"keyword": "ì•„ì´", "score": 890, "search_count": 84000},
                {"keyword": "ìœ ì¹˜ì›", "score": 860, "search_count": 81000},
                {"keyword": "ì´ˆë“±í•™êµ", "score": 830, "search_count": 78000},
                {"keyword": "í•™ì›", "score": 800, "search_count": 75000},
                {"keyword": "ì§‘", "score": 770, "search_count": 72000},
                {"keyword": "ì•„íŒŒíŠ¸", "score": 740, "search_count": 69000},
                {"keyword": "ë¶„ì–‘", "score": 710, "search_count": 66000},
                {"keyword": "ì¸í…Œë¦¬ì–´", "score": 680, "search_count": 63000},
                {"keyword": "ê°€ì „ì œí’ˆ", "score": 650, "search_count": 60000},
                {"keyword": "ì°¨", "score": 620, "search_count": 57000},
                {"keyword": "ë³´í—˜", "score": 590, "search_count": 54000},
                {"keyword": "ê±´ê°•", "score": 560, "search_count": 51000},
                {"keyword": "ìš´ë™", "score": 530, "search_count": 48000}
            ],
            "40ëŒ€": [
                {"keyword": "ê±´ê°•", "score": 980, "search_count": 95000},
                {"keyword": "ìš´ë™", "score": 950, "search_count": 92000},
                {"keyword": "ë‹¤ì´ì–´íŠ¸", "score": 920, "search_count": 89000},
                {"keyword": "ìš”ë¦¬", "score": 890, "search_count": 86000},
                {"keyword": "ë² ì´í‚¹", "score": 860, "search_count": 83000},
                {"keyword": "ì·¨ë¯¸", "score": 830, "search_count": 80000},
                {"keyword": "ë…ì„œ", "score": 800, "search_count": 77000},
                {"keyword": "ì˜í™”", "score": 770, "search_count": 74000},
                {"keyword": "ë“œë¼ë§ˆ", "score": 740, "search_count": 71000},
                {"keyword": "ì§‘", "score": 710, "search_count": 68000},
                {"keyword": "ì•„íŒŒíŠ¸", "score": 680, "search_count": 65000},
                {"keyword": "ì°¨", "score": 650, "search_count": 62000},
                {"keyword": "ë³´í—˜", "score": 620, "search_count": 59000},
                {"keyword": "íˆ¬ì", "score": 590, "search_count": 56000},
                {"keyword": "ë¶€ëª¨ë‹˜", "score": 560, "search_count": 53000}
            ],
            "50ëŒ€+": [
                {"keyword": "ê±´ê°•", "score": 1000, "search_count": 100000},
                {"keyword": "ìš´ë™", "score": 970, "search_count": 97000},
                {"keyword": "ë‹¤ì´ì–´íŠ¸", "score": 940, "search_count": 94000},
                {"keyword": "ìš”ë¦¬", "score": 910, "search_count": 91000},
                {"keyword": "ì·¨ë¯¸", "score": 880, "search_count": 88000},
                {"keyword": "ë…ì„œ", "score": 850, "search_count": 85000},
                {"keyword": "ì˜í™”", "score": 820, "search_count": 82000},
                {"keyword": "ì§‘", "score": 790, "search_count": 79000},
                {"keyword": "ì•„íŒŒíŠ¸", "score": 760, "search_count": 76000},
                {"keyword": "ì°¨", "score": 730, "search_count": 73000},
                {"keyword": "ë³´í—˜", "score": 700, "search_count": 70000},
                {"keyword": "íˆ¬ì", "score": 670, "search_count": 67000},
                {"keyword": "ë¶€ëª¨ë‹˜", "score": 640, "search_count": 64000},
                {"keyword": "íš¨ë„", "score": 610, "search_count": 61000},
                {"keyword": "ë…¸í›„", "score": 580, "search_count": 58000}
            ]
        }

    async def analyze_keywords_by_age_group(
        self, 
        max_results: int = 20,
        platforms: List[str] = None
    ) -> List[AgeGroupKeywordResponse]:
        """
        ì—°ë ¹ëŒ€ë³„ í‚¤ì›Œë“œ ë¶„ì„
        
        Args:
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            platforms: ë¶„ì„í•  í”Œë«í¼ ëª©ë¡
            
        Returns:
            ì—°ë ¹ëŒ€ë³„ í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼
        """
        if platforms is None:
            platforms = ["youtube", "tiktok", "instagram"]
            
        try:
            # ì‹¤ì œ API í˜¸ì¶œ ëŒ€ì‹  ë”ë¯¸ ë°ì´í„° ìƒì„±
            age_group_results = []
            
            for age_group, patterns in self.age_group_patterns.items():
                # í•´ë‹¹ ì—°ë ¹ëŒ€ì˜ í‚¤ì›Œë“œ ë°ì´í„° ìƒì„±
                age_keywords = self._generate_age_group_keywords(age_group, patterns, max_results)
                
                # í”Œë«í¼ë³„ ë¶„í¬ ê³„ì‚°
                platform_distribution = self._calculate_platform_distribution(
                    age_keywords, platforms
                )
                
                # íŠ¸ë Œë”© ì ìˆ˜ ê³„ì‚°
                trending_score = self._calculate_trending_score(age_keywords)
                
                result = AgeGroupKeywordResponse(
                    age_group=age_group,
                    keywords=age_keywords,
                    total_searches=sum(kw.get("search_count", 0) for kw in age_keywords),
                    platform_distribution=platform_distribution,
                    trending_score=trending_score,
                    timestamp=datetime.now()
                )
                
                age_group_results.append(result)
            
            return age_group_results
            
        except Exception as e:
            raise Exception(f"ì—°ë ¹ëŒ€ë³„ í‚¤ì›Œë“œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

    async def analyze_specific_keyword(
        self, 
        keyword: str,
        platforms: List[str] = None
    ) -> KeywordAnalysisResponse:
        """
        íŠ¹ì • í‚¤ì›Œë“œì˜ ì—°ë ¹ëŒ€ë³„ ë¶„ì„
        
        Args:
            keyword: ë¶„ì„í•  í‚¤ì›Œë“œ
            platforms: ë¶„ì„í•  í”Œë«í¼ ëª©ë¡
            
        Returns:
            í‚¤ì›Œë“œë³„ ì—°ë ¹ëŒ€ ë¶„ì„ ê²°ê³¼
        """
        if platforms is None:
            platforms = ["youtube", "tiktok", "instagram"]
            
        try:
            # ë”ë¯¸ ë°ì´í„°ë¡œ í‚¤ì›Œë“œ ë¶„ì„ ìƒì„±
            age_groups_analysis = {}
            total_mentions = 0
            platform_breakdown = defaultdict(int)
            
            for age_group, patterns in self.age_group_patterns.items():
                # í•´ë‹¹ ì—°ë ¹ëŒ€ì—ì„œì˜ í‚¤ì›Œë“œ ë¶„ì„ (ë”ë¯¸ ë°ì´í„°)
                age_analysis = self._generate_keyword_analysis_for_age_group(
                    keyword, age_group, patterns
                )
                
                age_groups_analysis[age_group] = age_analysis
                total_mentions += age_analysis.get("mentions", 0)
                
                # í”Œë«í¼ë³„ ë¶„í¬ ëˆ„ì 
                for platform, count in age_analysis.get("platform_mentions", {}).items():
                    platform_breakdown[platform] += count
            
            # íŠ¸ë Œë“œ ë°©í–¥ ë¶„ì„ (ë”ë¯¸)
            trending_trend = self._generate_trending_direction(keyword)
            
            # ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì¶œ (ë”ë¯¸)
            related_keywords = self._generate_related_keywords(keyword)
            
            # ê°ì • ì ìˆ˜ ê³„ì‚° (ë”ë¯¸)
            sentiment_score = self._generate_sentiment_score(keyword)
            
            return KeywordAnalysisResponse(
                keyword=keyword,
                age_groups=age_groups_analysis,
                total_mentions=total_mentions,
                platform_breakdown=dict(platform_breakdown),
                trending_trend=trending_trend,
                related_keywords=related_keywords,
                sentiment_score=sentiment_score,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            raise Exception(f"í‚¤ì›Œë“œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

    async def get_age_group_trends(
        self, 
        age_group: str,
        max_results: int = 15
    ) -> AgeGroupTrendResponse:
        """
        íŠ¹ì • ì—°ë ¹ëŒ€ì˜ íŠ¸ë Œë“œ ë¶„ì„
        
        Args:
            age_group: ë¶„ì„í•  ì—°ë ¹ëŒ€
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            ì—°ë ¹ëŒ€ë³„ íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼
        """
        try:
            if age_group not in self.age_group_patterns:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì—°ë ¹ëŒ€: {age_group}")
            
            patterns = self.age_group_patterns[age_group]
            platforms = patterns["platforms"]
            
            # í•´ë‹¹ ì—°ë ¹ëŒ€ì— ë§ëŠ” íŠ¸ë Œë“œ ìˆ˜ì§‘
            trends = await self._collect_age_specific_trends(
                age_group, patterns, platforms, max_results
            )
            
            # ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ
            top_keywords = self._extract_top_keywords(trends, max_results)
            
            # íŠ¸ë Œë”© í† í”½ ë¶„ì„
            trending_topics = self._analyze_trending_topics(trends)
            
            # í”Œë«í¼ ì„ í˜¸ë„ ê³„ì‚°
            platform_preferences = self._calculate_platform_preferences(trends, platforms)
            
            # ì½˜í…ì¸  ì¹´í…Œê³ ë¦¬ ë¶„í¬
            content_categories = self._analyze_content_categories(trends)
            
            return AgeGroupTrendResponse(
                age_group=age_group,
                top_keywords=top_keywords,
                trending_topics=trending_topics,
                platform_preferences=platform_preferences,
                content_categories=content_categories,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            raise Exception(f"ì—°ë ¹ëŒ€ íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

    async def _collect_trends_from_platforms(
        self, 
        platforms: List[str], 
        max_results: int
    ) -> List[Dict[str, Any]]:
        """í”Œë«í¼ë³„ íŠ¸ë Œë“œ ë°ì´í„° ìˆ˜ì§‘"""
        all_trends = []
        
        for platform in platforms:
            try:
                if platform == "youtube":
                    trends = await self.youtube_service.get_trending_videos(max_results=max_results)
                elif platform == "tiktok":
                    trends = await self.tiktok_service.get_trending_videos(max_results=max_results)
                elif platform == "instagram":
                    trends = await self.instagram_service.get_trending_posts(max_results=max_results)
                else:
                    continue
                
                # í”Œë«í¼ ì •ë³´ ì¶”ê°€
                for trend in trends:
                    trend_dict = trend.dict() if hasattr(trend, 'dict') else trend
                    trend_dict['platform'] = platform
                    all_trends.append(trend_dict)
                    
            except Exception as e:
                print(f"{platform} íŠ¸ë Œë“œ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                continue
        
        return all_trends

    async def _analyze_age_group_keywords(
        self, 
        trends: List[Dict[str, Any]], 
        age_group: str, 
        patterns: Dict[str, Any], 
        max_results: int
    ) -> List[Dict[str, Any]]:
        """ì—°ë ¹ëŒ€ë³„ í‚¤ì›Œë“œ ë¶„ì„"""
        age_keywords = []
        keyword_scores = defaultdict(float)
        
        # ì—°ë ¹ëŒ€ë³„ í‚¤ì›Œë“œ íŒ¨í„´ ë§¤ì¹­
        for trend in trends:
            title = trend.get('title', '').lower()
            description = trend.get('description', '').lower()
            tags = trend.get('tags', [])
            hashtags = trend.get('hashtags', [])
            
            # í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            text_content = f"{title} {description} {' '.join(tags)} {' '.join(hashtags)}"
            
            # ì—°ë ¹ëŒ€ë³„ í‚¤ì›Œë“œ ë§¤ì¹­
            for keyword in patterns["keywords"]:
                if keyword.lower() in text_content:
                    platform = trend.get('platform', 'unknown')
                    platform_weight = self.platform_weights.get(platform, 1.0)
                    age_weight = patterns["weight"]
                    
                    # ì ìˆ˜ ê³„ì‚° (ì¡°íšŒìˆ˜, ì¢‹ì•„ìš” ìˆ˜ ë“± ê³ ë ¤)
                    engagement_score = self._calculate_engagement_score(trend)
                    keyword_scores[keyword] += engagement_score * platform_weight * age_weight
        
        # ìƒìœ„ í‚¤ì›Œë“œ ì„ íƒ
        sorted_keywords = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)
        
        for keyword, score in sorted_keywords[:max_results]:
            age_keywords.append({
                "keyword": keyword,
                "score": round(score, 2),
                "search_count": int(score * 100),  # ê°€ìƒì˜ ê²€ìƒ‰ ìˆ˜
                "trending_level": self._get_trending_level(score)
            })
        
        return age_keywords

    def _calculate_engagement_score(self, trend: Dict[str, Any]) -> float:
        """ì°¸ì—¬ë„ ì ìˆ˜ ê³„ì‚°"""
        view_count = trend.get('view_count', 0) or 0
        like_count = trend.get('like_count', 0) or 0
        comment_count = trend.get('comment_count', 0) or 0
        share_count = trend.get('share_count', 0) or 0
        
        # ê°€ì¤‘ì¹˜ ì ìš©
        score = (view_count * 0.1 + like_count * 0.3 + comment_count * 0.4 + share_count * 0.2)
        return min(score, 1000)  # ìµœëŒ€ê°’ ì œí•œ

    def _get_trending_level(self, score: float) -> str:
        """íŠ¸ë Œë”© ë ˆë²¨ íŒì •"""
        if score > 500:
            return "ğŸ”¥ ë§¤ìš° ì¸ê¸°"
        elif score > 200:
            return "ğŸ“ˆ ì¸ê¸° ìƒìŠ¹"
        elif score > 50:
            return "ğŸ“Š ê´€ì‹¬ ì¦ê°€"
        else:
            return "ğŸ“‹ ì¼ë°˜"

    def _calculate_platform_distribution(
        self, 
        keywords: List[Dict[str, Any]], 
        platforms: List[str]
    ) -> Dict[str, int]:
        """í”Œë«í¼ë³„ ë¶„í¬ ê³„ì‚°"""
        distribution = {platform: 0 for platform in platforms}
        
        # í‚¤ì›Œë“œ ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í”Œë«í¼ë³„ ë¶„í¬ ì¶”ì •
        total_score = sum(kw.get("score", 0) for kw in keywords)
        if total_score > 0:
            for platform in platforms:
                platform_weight = self.platform_weights.get(platform, 1.0)
                distribution[platform] = int(total_score * platform_weight / len(platforms))
        
        return distribution

    def _calculate_trending_score(self, keywords: List[Dict[str, Any]]) -> float:
        """íŠ¸ë Œë”© ì ìˆ˜ ê³„ì‚°"""
        if not keywords:
            return 0.0
        
        total_score = sum(kw.get("score", 0) for kw in keywords)
        avg_score = total_score / len(keywords)
        
        # ì •ê·œí™” (0-100 ë²”ìœ„)
        return min(round(avg_score / 10, 2), 100.0)

    async def _search_keyword_across_platforms(
        self, 
        keyword: str, 
        platforms: List[str]
    ) -> List[Dict[str, Any]]:
        """í”Œë«í¼ë³„ í‚¤ì›Œë“œ ê²€ìƒ‰"""
        search_results = []
        
        for platform in platforms:
            try:
                if platform == "youtube":
                    results = await self.youtube_service.search_videos(query=keyword, max_results=20)
                elif platform == "tiktok":
                    results = await self.tiktok_service.search_videos(query=keyword, max_results=20)
                elif platform == "instagram":
                    results = await self.instagram_service.search_posts(query=keyword, max_results=20)
                else:
                    continue
                
                # í”Œë«í¼ ì •ë³´ ì¶”ê°€
                for result in results:
                    result_dict = result.dict() if hasattr(result, 'dict') else result
                    result_dict['platform'] = platform
                    search_results.append(result_dict)
                    
            except Exception as e:
                print(f"{platform} í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
                continue
        
        return search_results

    async def _analyze_keyword_for_age_group(
        self, 
        search_results: List[Dict[str, Any]], 
        keyword: str, 
        age_group: str, 
        patterns: Dict[str, Any]
    ) -> Dict[str, Any]:
        """íŠ¹ì • ì—°ë ¹ëŒ€ì—ì„œì˜ í‚¤ì›Œë“œ ë¶„ì„"""
        mentions = 0
        platform_mentions = defaultdict(int)
        engagement_score = 0
        
        for result in search_results:
            title = result.get('title', '').lower()
            description = result.get('description', '').lower()
            platform = result.get('platform', '')
            
            # í‚¤ì›Œë“œ ì–¸ê¸‰ í™•ì¸
            if keyword.lower() in title or keyword.lower() in description:
                mentions += 1
                platform_mentions[platform] += 1
                
                # ì°¸ì—¬ë„ ì ìˆ˜ ê³„ì‚°
                engagement_score += self._calculate_engagement_score(result)
        
        # ì—°ë ¹ëŒ€ë³„ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
        relevance_score = self._calculate_age_relevance(keyword, age_group, patterns)
        
        return {
            "mentions": mentions,
            "platform_mentions": dict(platform_mentions),
            "engagement_score": round(engagement_score, 2),
            "relevance_score": round(relevance_score, 2),
            "trending_level": self._get_trending_level(engagement_score)
        }

    def _calculate_age_relevance(
        self, 
        keyword: str, 
        age_group: str, 
        patterns: Dict[str, Any]
    ) -> float:
        """ì—°ë ¹ëŒ€ë³„ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        if keyword.lower() in [kw.lower() for kw in patterns["keywords"]]:
            return patterns["weight"] * 100
        else:
            # ë¶€ë¶„ ë§¤ì¹­ í™•ì¸
            for pattern_keyword in patterns["keywords"]:
                if keyword.lower() in pattern_keyword.lower() or pattern_keyword.lower() in keyword.lower():
                    return patterns["weight"] * 50
            return 10.0  # ê¸°ë³¸ ì ìˆ˜

    def _analyze_trending_direction(self, search_results: List[Dict[str, Any]]) -> str:
        """íŠ¸ë Œë“œ ë°©í–¥ ë¶„ì„"""
        if not search_results:
            return "ìœ ì§€"
        
        # ìµœê·¼ ì½˜í…ì¸  ë¹„ìœ¨ë¡œ íŠ¸ë Œë“œ ë°©í–¥ ì¶”ì •
        recent_count = 0
        total_count = len(search_results)
        
        for result in search_results:
            published_at = result.get('published_at')
            if published_at:
                # ìµœê·¼ 7ì¼ ë‚´ ì½˜í…ì¸  í™•ì¸
                if isinstance(published_at, str):
                    try:
                        published_date = datetime.fromisoformat(published_at.replace('Z', '+00:00'))
                        if datetime.now(published_date.tzinfo) - published_date < timedelta(days=7):
                            recent_count += 1
                    except:
                        pass
        
        recent_ratio = recent_count / total_count if total_count > 0 else 0
        
        if recent_ratio > 0.6:
            return "ìƒìŠ¹"
        elif recent_ratio > 0.3:
            return "ìœ ì§€"
        else:
            return "í•˜ë½"

    def _extract_related_keywords(self, search_results: List[Dict[str, Any]]) -> List[str]:
        """ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        all_text = ""
        for result in search_results:
            title = result.get('title', '')
            description = result.get('description', '')
            tags = ' '.join(result.get('tags', []))
            hashtags = ' '.join(result.get('hashtags', []))
            all_text += f"{title} {description} {tags} {hashtags} "
        
        # í•œêµ­ì–´ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ì •ê·œì‹)
        korean_words = re.findall(r'[ê°€-í£]{2,}', all_text)
        word_counts = Counter(korean_words)
        
        # ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ ë°˜í™˜
        return [word for word, count in word_counts.most_common(10)]

    def _calculate_sentiment_score(
        self, 
        keyword: str, 
        search_results: List[Dict[str, Any]]
    ) -> float:
        """ê°ì • ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)"""
        positive_words = ['ì¢‹ë‹¤', 'ìµœê³ ', 'ëŒ€ë°•', 'ì™„ë²½', 'ì‚¬ë‘', 'ì¶”ì²œ', 'ì¸ê¸°', 'ì„±ê³µ']
        negative_words = ['ë‚˜ì˜ë‹¤', 'ìµœì•…', 'ì‹¤íŒ¨', 'ë³„ë¡œ', 'ì‹«ë‹¤', 'ë¬¸ì œ', 'ì‹¤ë§', 'ì‹¤íŒ¨']
        
        all_text = ""
        for result in search_results:
            title = result.get('title', '')
            description = result.get('description', '')
            all_text += f"{title} {description} "
        
        positive_count = sum(1 for word in positive_words if word in all_text)
        negative_count = sum(1 for word in negative_words if word in all_text)
        
        total = positive_count + negative_count
        if total == 0:
            return 0.0
        
        return round((positive_count - negative_count) / total, 2)

    async def _collect_age_specific_trends(
        self, 
        age_group: str, 
        patterns: Dict[str, Any], 
        platforms: List[str], 
        max_results: int
    ) -> List[Dict[str, Any]]:
        """ì—°ë ¹ëŒ€ë³„ íŠ¹í™” íŠ¸ë Œë“œ ìˆ˜ì§‘"""
        trends = await self._collect_trends_from_platforms(platforms, max_results * 2)
        
        # ì—°ë ¹ëŒ€ì— ë§ëŠ” íŠ¸ë Œë“œ í•„í„°ë§
        filtered_trends = []
        for trend in trends:
            title = trend.get('title', '').lower()
            description = trend.get('description', '').lower()
            text_content = f"{title} {description}"
            
            # ì—°ë ¹ëŒ€ í‚¤ì›Œë“œì™€ ë§¤ì¹­ë˜ëŠ” íŠ¸ë Œë“œë§Œ ì„ íƒ
            for keyword in patterns["keywords"]:
                if keyword.lower() in text_content:
                    filtered_trends.append(trend)
                    break
        
        return filtered_trends[:max_results]

    def _extract_top_keywords(
        self, 
        trends: List[Dict[str, Any]], 
        max_results: int
    ) -> List[Dict[str, Any]]:
        """ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keyword_scores = defaultdict(float)
        
        for trend in trends:
            title = trend.get('title', '')
            description = trend.get('description', '')
            tags = trend.get('tags', [])
            hashtags = trend.get('hashtags', [])
            
            # í•œêµ­ì–´ í‚¤ì›Œë“œ ì¶”ì¶œ
            text_content = f"{title} {description} {' '.join(tags)} {' '.join(hashtags)}"
            korean_words = re.findall(r'[ê°€-í£]{2,}', text_content)
            
            engagement_score = self._calculate_engagement_score(trend)
            
            for word in korean_words:
                if len(word) >= 2:  # 2ê¸€ì ì´ìƒë§Œ
                    keyword_scores[word] += engagement_score
        
        # ìƒìœ„ í‚¤ì›Œë“œ ë°˜í™˜
        sorted_keywords = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)
        return [
            {
                "keyword": keyword,
                "score": round(score, 2),
                "trending_level": self._get_trending_level(score)
            }
            for keyword, score in sorted_keywords[:max_results]
        ]

    def _analyze_trending_topics(self, trends: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """íŠ¸ë Œë”© í† í”½ ë¶„ì„"""
        topics = defaultdict(lambda: {"count": 0, "engagement": 0})
        
        for trend in trends:
            category = trend.get('category', 'ê¸°íƒ€')
            engagement = self._calculate_engagement_score(trend)
            
            topics[category]["count"] += 1
            topics[category]["engagement"] += engagement
        
        return [
            {
                "topic": topic,
                "count": data["count"],
                "engagement": round(data["engagement"], 2),
                "avg_engagement": round(data["engagement"] / data["count"], 2) if data["count"] > 0 else 0
            }
            for topic, data in sorted(topics.items(), key=lambda x: x[1]["engagement"], reverse=True)
        ]

    def _calculate_platform_preferences(
        self, 
        trends: List[Dict[str, Any]], 
        platforms: List[str]
    ) -> Dict[str, float]:
        """í”Œë«í¼ ì„ í˜¸ë„ ê³„ì‚°"""
        platform_counts = defaultdict(int)
        total_count = len(trends)
        
        for trend in trends:
            platform = trend.get('platform', 'unknown')
            platform_counts[platform] += 1
        
        preferences = {}
        for platform in platforms:
            count = platform_counts[platform]
            preferences[platform] = round(count / total_count * 100, 2) if total_count > 0 else 0
        
        return preferences

    def _analyze_content_categories(self, trends: List[Dict[str, Any]]) -> Dict[str, int]:
        """ì½˜í…ì¸  ì¹´í…Œê³ ë¦¬ ë¶„í¬ ë¶„ì„"""
        categories = defaultdict(int)
        
        for trend in trends:
            category = trend.get('category', 'ê¸°íƒ€')
            categories[category] += 1
        
        return dict(categories)

    def _generate_age_group_keywords(
        self, 
        age_group: str, 
        patterns: Dict[str, Any], 
        max_results: int
    ) -> List[Dict[str, Any]]:
        """ì—°ë ¹ëŒ€ë³„ í‚¤ì›Œë“œ ë°ì´í„° ìƒì„± (ë”ë¯¸ ë°ì´í„°)"""
        if age_group in self.age_group_popular_keywords:
            keywords = self.age_group_popular_keywords[age_group][:max_results]
        else:
            # ê¸°ë³¸ í‚¤ì›Œë“œ ìƒì„±
            keywords = []
            for i, keyword in enumerate(patterns["keywords"][:max_results]):
                score = 1000 - (i * 50)  # ì ìˆ˜ ê°ì†Œ
                keywords.append({
                    "keyword": keyword,
                    "score": score,
                    "search_count": int(score * 100),
                    "trending_level": self._get_trending_level(score)
                })
        
        # íŠ¸ë Œë”© ë ˆë²¨ ì¶”ê°€
        for keyword in keywords:
            if "trending_level" not in keyword:
                keyword["trending_level"] = self._get_trending_level(keyword["score"])
        
        return keywords

    def _generate_keyword_analysis_for_age_group(
        self, 
        keyword: str, 
        age_group: str, 
        patterns: Dict[str, Any]
    ) -> Dict[str, Any]:
        """íŠ¹ì • ì—°ë ¹ëŒ€ì—ì„œì˜ í‚¤ì›Œë“œ ë¶„ì„ (ë”ë¯¸ ë°ì´í„°)"""
        # í‚¤ì›Œë“œê°€ í•´ë‹¹ ì—°ë ¹ëŒ€ íŒ¨í„´ì— ìˆëŠ”ì§€ í™•ì¸
        relevance_score = self._calculate_age_relevance(keyword, age_group, patterns)
        
        # ë”ë¯¸ ë°ì´í„° ìƒì„±
        mentions = int(relevance_score / 10) + 5  # ê´€ë ¨ì„± ì ìˆ˜ ê¸°ë°˜
        platform_mentions = {}
        
        for platform in patterns["platforms"]:
            platform_mentions[platform] = mentions // len(patterns["platforms"])
        
        engagement_score = relevance_score * 10
        
        return {
            "mentions": mentions,
            "platform_mentions": platform_mentions,
            "engagement_score": round(engagement_score, 2),
            "relevance_score": round(relevance_score, 2),
            "trending_level": self._get_trending_level(engagement_score)
        }

    def _generate_trending_direction(self, keyword: str) -> str:
        """íŠ¸ë Œë“œ ë°©í–¥ ìƒì„± (ë”ë¯¸ ë°ì´í„°)"""
        # í‚¤ì›Œë“œ ê¸¸ì´ì™€ ë‚´ìš©ì— ë”°ë¼ íŠ¸ë Œë“œ ë°©í–¥ ê²°ì •
        if len(keyword) > 5:
            return "ìƒìŠ¹"
        elif len(keyword) > 3:
            return "ìœ ì§€"
        else:
            return "í•˜ë½"

    def _generate_related_keywords(self, keyword: str) -> List[str]:
        """ê´€ë ¨ í‚¤ì›Œë“œ ìƒì„± (ë”ë¯¸ ë°ì´í„°)"""
        # í‚¤ì›Œë“œë³„ ê´€ë ¨ í‚¤ì›Œë“œ ë§¤í•‘
        related_keywords_map = {
            "ê²Œì„": ["ê²Œì„", "í”Œë ˆì´", "ìŠ¤íŒ€", "ì½˜ì†”", "ëª¨ë°”ì¼ê²Œì„"],
            "ì·¨ì—…": ["ì´ë ¥ì„œ", "ë©´ì ‘", "ìŠ¤íƒ€íŠ¸ì—…", "ì—°ë´‰", "ë³µì§€"],
            "ê²°í˜¼": ["ì›¨ë”©", "ì‹ í˜¼", "ìœ¡ì•„", "ê°€ì¡±", "ë¶€ë¶€"],
            "ê±´ê°•": ["ìš´ë™", "ë‹¤ì´ì–´íŠ¸", "ë³‘ì›", "ì•½", "ê²€ì§„"],
            "ì§‘": ["ì•„íŒŒíŠ¸", "ë¶„ì–‘", "ì¸í…Œë¦¬ì–´", "ê°€ì „ì œí’ˆ", "ê°€êµ¬"],
            "ì°¨": ["ìë™ì°¨", "ë³´í—˜", "ì •ë¹„", "ì£¼ìœ ", "ì£¼ì°¨"]
        }
        
        # ê¸°ë³¸ ê´€ë ¨ í‚¤ì›Œë“œ
        default_related = ["ê´€ë ¨", "ìœ ì‚¬", "ë¹„ìŠ·", "ì—°ê´€", "ê´€ê³„"]
        
        for key, related in related_keywords_map.items():
            if key in keyword:
                return related[:5]
        
        return default_related[:5]

    def _generate_sentiment_score(self, keyword: str) -> float:
        """ê°ì • ì ìˆ˜ ìƒì„± (ë”ë¯¸ ë°ì´í„°)"""
        # ê¸ì •ì  í‚¤ì›Œë“œ
        positive_keywords = ["ì¢‹ë‹¤", "ìµœê³ ", "ëŒ€ë°•", "ì™„ë²½", "ì‚¬ë‘", "ì¶”ì²œ", "ì¸ê¸°", "ì„±ê³µ", "í–‰ë³µ"]
        # ë¶€ì •ì  í‚¤ì›Œë“œ
        negative_keywords = ["ë‚˜ì˜ë‹¤", "ìµœì•…", "ì‹¤íŒ¨", "ë³„ë¡œ", "ì‹«ë‹¤", "ë¬¸ì œ", "ì‹¤ë§", "ì‹¤íŒ¨", "ìŠ¤íŠ¸ë ˆìŠ¤"]
        
        keyword_lower = keyword.lower()
        
        for pos_word in positive_keywords:
            if pos_word in keyword_lower:
                return 0.8
        
        for neg_word in negative_keywords:
            if neg_word in keyword_lower:
                return -0.6
        
        # ì¤‘ë¦½ì  í‚¤ì›Œë“œëŠ” 0.1 ì •ë„ì˜ ì•½ê°„ ê¸ì •ì  ì ìˆ˜
        return 0.1 